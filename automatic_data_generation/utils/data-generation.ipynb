{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "cmap = plt.get_cmap('viridis')\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = '/Users/stephane/Dropbox/Work/Codes/snips/automatic-data-generation/automatic_data_generation/'\n",
    "dataroot = workdir + 'data/'\n",
    "os.chdir(workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.embedding import Datasets\n",
    "datasets = Datasets(train_path=dataroot+'snips/train.csv', valid_path=dataroot+'snips/validate.csv', emb_dim=100, tokenizer='nltk')\n",
    "vocab = datasets.DELEX.vocab\n",
    "i2w = vocab.itos\n",
    "w2i = vocab.stoi\n",
    "sos_idx = w2i['<sos>']\n",
    "eos_idx = w2i['<eos>']\n",
    "pad_idx = w2i['<pad>']\n",
    "unk_idx = w2i['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<pad>',\n",
       " '<sos>',\n",
       " '<eos>',\n",
       " 'the',\n",
       " 'a',\n",
       " 'to',\n",
       " '_object_type_',\n",
       " 'for',\n",
       " '_object_name_',\n",
       " 'in',\n",
       " '_playlist_',\n",
       " 'i',\n",
       " 'at',\n",
       " '_timerange_',\n",
       " '_rating_value_',\n",
       " '_artist_',\n",
       " 'play',\n",
       " '_music_item_',\n",
       " 'of']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2w[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Karpathy CharRNN\n",
    "\n",
    "### Temperature: 0.2\n",
    "\n",
    "I want to book a reservation for a restaurant for a party of a party of 6 points\n",
    "\n",
    "I want to book a reservation for a restaurant for a restaurant for a restaurant in Barken Marcha at a party of 6\n",
    "\n",
    "I need a table for a restaurant for a party of a party of 6 points\n",
    "\n",
    "### Temperature: 0.5\n",
    "I need a table for a reservation for a restaurant in the area that serves find movement in the area at a party of a siming from now\n",
    "\n",
    "I want to half album to Musaf Rock Story Barb playlist.\n",
    "\n",
    "I want to give this current book The Very Satarora for the twenty-textbook.\n",
    "\n",
    "### Temperature: 1.0\n",
    "What will the weather be syar llind in Playlin Man.\n",
    "\n",
    "Tell it i from the Shawnua Tf Hiss Morny Cimes\n",
    "\n",
    "Hadon in a top-fight?\n",
    "\n",
    "play the song from the fifties for ten in Mondital Maker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "run = torch.load('run.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (cvae.py, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/stephane/Dropbox/Work/Codes/snips/automatic-data-generation/automatic_data_generation/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3296\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-9-436f471fc338>\"\u001b[0m, line \u001b[1;32m11\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from train import anneal_fn\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/stephane/Dropbox/Work/Codes/snips/automatic-data-generation/automatic_data_generation/train.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import automatic_data_generation.models.cvae as models\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/stephane/Dropbox/Work/Codes/snips/automatic-data-generation/automatic_data_generation/models/cvae.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <import torch\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axarr = plt.subplots(1,4, figsize=(20,6))\n",
    "axarr = axarr.flatten()\n",
    "\n",
    "args = run['args']\n",
    "NLL_hist = run['NLL_hist']\n",
    "KL_hist  = run['KL_hist' ]\n",
    "NMI_hist = run['NMI_hist']\n",
    "acc_hist = run['acc_hist']\n",
    "t = np.array(range(len(NLL_hist)))\n",
    "\n",
    "from train import anneal_fn\n",
    "anneal_fn = np.vectorize(anneal_fn)\n",
    "KL_weight = anneal_fn(args.anneal_function, t, args.k1, args.x1, args.m1)\n",
    "label_weight = anneal_fn(args.anneal_function, t, args.k2, args.x2, args.m2)\n",
    "\n",
    "KL_hist = np.array(KL_hist)\n",
    "axarr[0].plot(t, NLL_hist )\n",
    "for i in range(args.latent_size):\n",
    "    axarr[1].semilogy(t, KL_hist[:,i], label=i)\n",
    "ax1bis = axarr[1].twinx()\n",
    "ax1bis.plot(t, KL_weight, color='red')\n",
    "axarr[2].plot(t, acc_hist )\n",
    "ax2bis = axarr[2].twinx()\n",
    "ax2bis.plot(t, label_weight, color='green')\n",
    "axarr[3].plot(t, NMI_hist)\n",
    "\n",
    "for i in range(3):\n",
    "    axarr[i].set_xlabel('Iterations')\n",
    "axarr[0].set_ylabel('Reconstruction loss')\n",
    "axarr[1].set_ylabel('KL loss')\n",
    "ax1bis.set_ylabel('KL_weight', color='red')\n",
    "axarr[2].set_ylabel('acc')\n",
    "ax2bis.set_ylabel('label_weight', color='green')\n",
    "axarr[3].set_ylabel('NMI')\n",
    "\n",
    "fig.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_per_intent = 2000\n",
    "\n",
    "latent = run['latent']\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "all_latent = sum([latent_list for latent_list in latent.values()], [])\n",
    "pca.fit(all_latent)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for intent in latent.keys():\n",
    "    points = pca.transform(latent[intent])\n",
    "    #points = np.array(latent[intent])\n",
    "    ax.scatter(points[:n_per_intent,0], points[:n_per_intent,1], points[:n_per_intent,2], c=[cmap(intent/len(latent.keys()))], label='{}'.format(intent))\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_start = 0\n",
    "n_end = 100\n",
    "words = run['i2w']\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(40,20))\n",
    "axarr = axarr.flatten()\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "for ax, stage in enumerate(['before', 'after']):\n",
    "    vectors = run['vectors'][stage]\n",
    "    pca = PCA(n_components=2)\n",
    "    proj = pca.fit_transform(vectors)\n",
    "    axarr[ax].scatter(proj[n_start:n_end,0], proj[n_start:n_end,1])\n",
    "    for i, word in enumerate(words[n_start:n_end]):\n",
    "        i += n_start\n",
    "        axarr[ax].annotate(word,xy=(proj[i,0], proj[i,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectories in latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automatic_data_generation.models.embedding import Datasets\n",
    "from automatic_data_generation.models.cvae import CVAE\n",
    "from automatic_data_generation.utils.utils import to_device, interpolate, idx2word\n",
    "\n",
    "run = torch.load('run.pkl')\n",
    "args = run['args']\n",
    "\n",
    "datadir = os.path.join('./data', args.dataset)\n",
    "train_path = os.path.join(datadir, 'train.csv')\n",
    "validate_path = os.path.join(datadir, 'validate.csv')\n",
    "datasets = Datasets(train_path=os.path.join(train_path), valid_path=os.path.join(validate_path), emb_dim=args.emb_dim, tokenizer=args.tokenizer)\n",
    "\n",
    "if args.input_type=='delexicalised':\n",
    "    print('embedding the slots with %s averaging' %args.slot_averaging)\n",
    "    datasets.embed_slots(args.slot_averaging)\n",
    "\n",
    "vocab = datasets.TEXT.vocab if args.input_type=='utterance' else datasets.DELEX.vocab\n",
    "i2w = vocab.itos\n",
    "w2i = vocab.stoi\n",
    "i2int = datasets.INTENT.vocab.itos\n",
    "int2i = datasets.INTENT.vocab.stoi\n",
    "n_classes = len(i2int)\n",
    "sos_idx = w2i['SOS']\n",
    "eos_idx = w2i['EOS']\n",
    "pad_idx = w2i['<pad>']\n",
    "unk_idx = w2i['<unk>']\n",
    "\n",
    "model = CVAE(\n",
    "        vocab_size=len(i2w),\n",
    "        max_sequence_length=args.max_sequence_length,\n",
    "        sos_idx=sos_idx,\n",
    "        eos_idx=eos_idx,\n",
    "        pad_idx=pad_idx,\n",
    "        unk_idx=unk_idx,\n",
    "        embedding_size=args.emb_dim,\n",
    "        rnn_type=args.rnn_type,\n",
    "        hidden_size=args.hidden_size,\n",
    "        word_dropout=args.word_dropout,\n",
    "        embedding_dropout=args.embedding_dropout,\n",
    "        z_size=args.latent_size,\n",
    "        n_classes=n_classes,\n",
    "        num_layers=args.num_layers,\n",
    "        bidirectional=args.bidirectional,\n",
    "        temperature=args.temperature,\n",
    "        conditional=False if args.conditional=='none' else True,\n",
    "        bow=args.bow_loss\n",
    "    )\n",
    "\n",
    "state_dict = torch.load(args.pickle+'.pyT')\n",
    "if state_dict['embedding.weight'].size(0) != model.embedding.weight.size(0): # vocab changed\n",
    "    state_dict['embedding.weight'] = vocab.vectors\n",
    "    state_dict['outputs2vocab.weight'] = torch.randn(len(i2w), args.hidden_size*model.hidden_factor)\n",
    "    state_dict['outputs2vocab.bias'] = torch.randn(len(i2w))\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "print('BLEU : ',run['bleu_scores'])\n",
    "print('Diversity : ',run['diversity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vary the continuous variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent = 2\n",
    "interp_dim = 8\n",
    "print(i2int[intent] + '\\n')\n",
    "\n",
    "#z1 = torch.randn([args.latent_size]).numpy()\n",
    "#z2 = torch.randn([args.latent_size]).numpy()\n",
    "z1 = torch.zeros([args.latent_size]).numpy()\n",
    "z2 = torch.zeros([args.latent_size]).numpy()\n",
    "z1[interp_dim] = -1\n",
    "z2[interp_dim] = +1\n",
    "z = to_device(torch.from_numpy(interpolate(start=z1, end=z2, steps=10)).float())\n",
    "batch_size=z.size(0)\n",
    "\n",
    "y_onehot = torch.zeros(batch_size, model.n_classes)\n",
    "y = torch.LongTensor(batch_size,1).fill_(intent)\n",
    "y_onehot.scatter_(1, y, 1)\n",
    "samples, z, y_onehot = model.inference(z=z, y_onehot=y_onehot)\n",
    "\n",
    "print('-------INTERPOLATION-------')\n",
    "print(*idx2word(samples, i2w=i2w, pad_idx=w2i['<pad>']), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vary the discrete variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-86f5ee3eba8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_onehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "z = torch.randn(model.n_classes,args.latent_size)\n",
    "\n",
    "y_onehot = torch.zeros(model.n_classes, model.n_classes)\n",
    "for i in range(model.n_classes):\n",
    "    y_onehot[i,i] = 1\n",
    "\n",
    "samples, z, y_onehot = model.inference(z=z, y_onehot=y_onehot)\n",
    "\n",
    "for intent, sentence in enumerate(idx2word(samples, i2w=i2w, pad_idx=w2i['<pad>'])):\n",
    "    print(i2int[intent])\n",
    "    print(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "target = torch.arange(0,5*64).view(64,-1)\n",
    "bow = torch.randn((64,500))\n",
    "\n",
    "loss = 0\n",
    "for b, t in zip(bow, target):\n",
    "    loss += torch.sum(b[t])\n",
    "print(loss)\n",
    "x = bow[:,target].view(64,64,)\n",
    "print(x.size())\n",
    "print(torch.einsum('iik->',(x)))\n",
    "    #print(np.sum([b[idx].numpy() for idx in t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py                        model.pyT\r\n",
      "__init__.pyc                       \u001b[34mmodels\u001b[m\u001b[m\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m                        \u001b[34mresults\u001b[m\u001b[m\r\n",
      "\u001b[34mautomatic_data_generation.egg-info\u001b[m\u001b[m run.pkl\r\n",
      "benchmark.py                       run.pyT\r\n",
      "\u001b[34mbuild\u001b[m\u001b[m                              train.py\r\n",
      "\u001b[34mdata\u001b[m\u001b[m                               \u001b[34mutils\u001b[m\u001b[m\r\n",
      "\u001b[34mdist\u001b[m\u001b[m                               utils.ipynb\r\n",
      "glove.6B.100d.txt                  \u001b[34mvenv\u001b[m\u001b[m\r\n",
      "\u001b[34mgrid\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
